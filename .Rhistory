#統計出現總頻次大於20且出現系所數不大於1/4系所總數的詞語數
length(which(cr1 & cr2 & cr3))
#刪除詞語，保留文件-詞語矩陣上出現總頻次大於20且出現系所數不大於1/4系所總數的詞語
dtm1 <- dtm[, cr1&cr2&cr3]
#統計每一筆文件上出現的詞語數
doc.termno = row_sums(dtm1)
#是否有沒有詞語的文件
which(doc.termno<=10)
length(which(doc.termno<=10))
length(which(doc.termno<=5))
dtm1 <- dtm1[doc.termno>5, ]
news.df1 <- news.df[doc.termno>5, ]
#產生亂數
SEED = as.integer(Sys.time())%%10000
#根據亂數值，切分文件為十等分
set.seed(SEED)
fold = 10
folding = sample(rep(seq_len(fold), ceiling(nrow(dtm1)))[seq_len(nrow(dtm1))])
chain.list = seq_len(fold)
#設定主題模型的主題數量
topics = seq(4, 30, 2)
cohDF = data.frame(num_topic=integer(), coherence=double())
doc_no <- nrow(dtm1)
for (ntopic  in topics) {
#LDA主題模型的參數
control_list = list(alpha=0.01, seed=SEED, burnin=1000, thin=100, iter=1000, best=FALSE)
#訓練LDA主題模型
model = LDA(dtm1, k = ntopic, control = control_list, method = "Gibbs")
#選擇目前模型內最佳模型
best_model = model@fitted[[which.max(logLik(model))]]
#主題內的詞語分布和文件內的主題分布
post_prob = posterior(best_model)
#將每個主題前10個最重要的詞語
term_no = 10
topicterm = terms(best_model, term_no)
coh = double(length=ntopic)
for (i in seq(1, ntopic)) {
t_idx <- sapply(topicterm[, i], function(x) which(dtm1$dimnames$Terms==x))
t_freq <- sapply(t_idx, function (x) length(which(dtm1$j==x))) / doc_no
t_docidx <- lapply(t_idx, function (x) dtm1$i[dtm1$j==x])
sum_pmi = 0
for (j in seq(1, term_no-1)) {
for (k in seq(j+1, term_no)) {
co_doc <- length(intersect(t_docidx[[j]], t_docidx[[k]])) / doc_no
pmi <- log(ifelse(co_doc>0,
co_doc/(t_freq[j]*t_freq[k]),
1e-12/(t_freq[j]*t_freq[k])))
sum_pmi = sum_pmi + pmi
}
}
coh[i] = sum_pmi*2 / (term_no*(term_no-1))
}
print(paste("ntopic:", ntopic, "Coherence:", mean(coh)))
cohDF = rbind(cohDF, data.frame(num_topic=ntopic, coherence=mean(coh)))
}
#以下利用10-fold cross validation計算不同主題數量下，每份語料在主題模型下的perplexity
#perpDF用來儲存每種主題數量、每份語料的perplexity
perpDF = data.frame(num_topic=integer(), chain=integer(), perplexity=double())
for (ntopic in topics) {
for (chain in chain.list) {
#LDA主題模型的參數
control_list = list(alpha=0.01, seed=SEED, burnin=1000, thin=100, iter=1000, best=FALSE)
#保留一份語料，以其餘的語料訓練LDA主題模型
training = LDA(dtm1[folding != chain,], k = ntopic, control = control_list, method = "Gibbs")
#選擇目前模型內最佳模型
best_training = training@fitted[[which.max(logLik(training))]]
#以最佳模型測試保留的語料
testing = LDA(dtm1[folding == chain,], model = best_training, control = list(estimate.beta = FALSE, seed = SEED, burnin = 1000, thin = 100, iter = 1000, best = FALSE))
#計算perplexity
perp = perplexity(testing, dtm1[folding == chain,], use_theta = FALSE)
print(paste0("topics: ", ntopic, ", folds: ", chain, ", perplexity: ", perp))
perpDF = rbind(perpDF, data.frame(num_topic=ntopic, chain=chain, perplexity=perp))
}
}
perpDF %>%
ggplot() +
geom_line(aes(x=num_topic, y=perplexity, colour=factor(chain), group=factor(chain)))
###
cohDF %>%
ggplot(aes(x=num_topic, y=coherence)) +
geom_line()
ntopic = 8
control_list = list(alpha=0.01, seed=SEED, burnin=1000, thin=100, iter=1000, best=FALSE)
model = LDA(dtm1, k = ntopic, control = control_list, method = "Gibbs")
best_model = model@fitted[[which.max(logLik(model))]]
## 各主題上的關鍵詞
term_no <- 10
topicterm = terms(best_model, term_no) %>%
t() %>%
as.data.frame(stringsAsFactors=FALSE) %>%
mutate(TopicName = rownames(.))
View(topicterm)
ntopic = 20
control_list = list(alpha=0.01, seed=SEED, burnin=1000, thin=100, iter=1000, best=FALSE)
model = LDA(dtm1, k = ntopic, control = control_list, method = "Gibbs")
best_model = model@fitted[[which.max(logLik(model))]]
## 各主題上的關鍵詞
term_no <- 10
topicterm = terms(best_model, term_no) %>%
t() %>%
as.data.frame(stringsAsFactors=FALSE) %>%
mutate(TopicName = rownames(.))
View(topicterm)
stopwords <- c("的", "在", "是", "都", "了", "之下", "不會",
"也", "很", "會", "有", "呢", "第二", "如何",
"嗎", "就", "但", "所", "我", "各項", "年來",
"不", "到", "要", "於", "表示", "增加", "而是",
"公里", "一名", "可能", "認為", "更是", "逐步",
"一次", "分享", "攝影", "繼續", "很多", "百年",
"這次", "近年", "特派記者", "隨著", "日益",
"就是", "沒有", "他們", "指出", "更加", "方面",
"整個", "任何", "不同", "本人", "充滿", "帶來",
"更好", "正在", "一天", "超過", "一直", "之外",
"再次", "對於", "曾經", "做出", "國人同胞",
"這塊", "儘管", "歷經", "如今", "各位伙伴",
"或者", "方式", "一向", "這樣", "各位鄉親",
"唯有", "來自", "英九", "一百年", "並且",
"登輝", "全體", "七年", "億元", "達到", "此外",
"絕對", "阿扁", "個人", "不管", "一切", "看到",
"親愛的國人同胞", "各位鄉親父老", "父老鄉親",
"什麼", "受到", "只有", "做到", "全體國人",
"起來", "我國", "民國", "年前", "所以", "謝謝",
"台灣人民", "願意", "相同", "依據", "院長",
"一方面", "同胞", "全國同胞", "決定", "如此",
"之間", "女士", "主席", "完全", "充分", "目前",
"只是", "始終", "通過", "大幅", "所謂", "之前",
"提高", "心中", "一部分", "不論是", "進一步",
"之際", "有關", "走過", "還有", "一塊", "三大",
"副總統", "相關", "各種", "甚至", "最近",
"打造一個", "以上", "然而", "兩千", "降到",
"因應", "需要", "由於", "當前", "最高", "一條",
"減少", "第一", "一位", "四年", "這種", "一代",
"全體國人同胞", "各位先進", "三年多", "非常",
"第三", "而且", "在於", "許多", "一起", "無法",
"包括", "因此", "各位貴賓", "大家好", "所有",
"今天是中華民國", "能夠", "不是", "不但",
"最大", "最後")
cr3 <- !(dtm$dimnames$Terms %in% stopwords)
length(which(cr3))
#統計出現總頻次大於20且出現系所數不大於1/4系所總數的詞語數
length(which(cr1 & cr2 & cr3))
#刪除詞語，保留文件-詞語矩陣上出現總頻次大於20且出現系所數不大於1/4系所總數的詞語
dtm1 <- dtm[, cr1&cr2&cr3]
#統計每一筆文件上出現的詞語數
doc.termno = row_sums(dtm1)
#是否有沒有詞語的文件
which(doc.termno<=5)
length(which(doc.termno<=5))
dtm1 <- dtm1[doc.termno>5, ]
news.df1 <- news.df[doc.termno>5, ]
#產生亂數
SEED = as.integer(Sys.time())%%10000
#根據亂數值，切分文件為十等分
set.seed(SEED)
ntopic = 20
control_list = list(alpha=0.01, seed=SEED, burnin=1000, thin=100, iter=1000, best=FALSE)
model = LDA(dtm1, k = ntopic, control = control_list, method = "Gibbs")
best_model = model@fitted[[which.max(logLik(model))]]
## 各主題上的關鍵詞
term_no <- 10
topicterm = terms(best_model, term_no) %>%
t() %>%
as.data.frame(stringsAsFactors=FALSE) %>%
mutate(TopicName = rownames(.))
stopwords <- c("的", "在", "是", "都", "了", "之下", "不會",
"也", "很", "會", "有", "呢", "第二", "如何",
"嗎", "就", "但", "所", "我", "各項", "年來",
"不", "到", "要", "於", "表示", "增加", "而是",
"公里", "一名", "可能", "認為", "更是", "逐步",
"一次", "分享", "攝影", "繼續", "很多", "百年",
"這次", "近年", "特派記者", "隨著", "日益",
"就是", "沒有", "他們", "指出", "更加", "方面",
"整個", "任何", "不同", "本人", "充滿", "帶來",
"更好", "正在", "一天", "超過", "一直", "之外",
"再次", "對於", "曾經", "做出", "國人同胞",
"這塊", "儘管", "歷經", "如今", "各位伙伴",
"或者", "方式", "一向", "這樣", "各位鄉親",
"唯有", "來自", "英九", "一百年", "並且",
"登輝", "全體", "七年", "億元", "達到", "此外",
"絕對", "阿扁", "個人", "不管", "一切", "看到",
"親愛的國人同胞", "各位鄉親父老", "父老鄉親",
"什麼", "受到", "只有", "做到", "全體國人",
"起來", "我國", "民國", "年前", "所以", "謝謝",
"台灣人民", "願意", "相同", "依據", "院長",
"一方面", "同胞", "全國同胞", "決定", "如此",
"之間", "女士", "主席", "完全", "充分", "目前",
"只是", "始終", "通過", "大幅", "所謂", "之前",
"提高", "心中", "一部分", "不論是", "進一步",
"之際", "有關", "走過", "還有", "一塊", "三大",
"副總統", "相關", "各種", "甚至", "最近",
"打造一個", "以上", "然而", "兩千", "降到",
"因應", "需要", "由於", "當前", "最高", "一條",
"減少", "第一", "一位", "四年", "這種", "一代",
"全體國人同胞", "各位先進", "三年多", "非常",
"第三", "而且", "在於", "許多", "一起", "無法",
"包括", "因此", "各位貴賓", "大家好", "所有",
"今天是中華民國", "能夠", "不是", "不但",
"最大", "最後", "終於", "先生", "只要", "除了")
cr3 <- !(dtm$dimnames$Terms %in% stopwords)
length(which(cr3))
#統計出現總頻次大於20且出現系所數不大於1/4系所總數的詞語數
length(which(cr1 & cr2 & cr3))
#刪除詞語，保留文件-詞語矩陣上出現總頻次大於20且出現系所數不大於1/4系所總數的詞語
dtm1 <- dtm[, cr1&cr2&cr3]
#統計每一筆文件上出現的詞語數
doc.termno = row_sums(dtm1)
#是否有沒有詞語的文件
which(doc.termno<=5)
length(which(doc.termno<=5))
dtm1 <- dtm1[doc.termno>5, ]
news.df1 <- news.df[doc.termno>5, ]
#產生亂數
SEED = as.integer(Sys.time())%%10000
#根據亂數值，切分文件為十等分
set.seed(SEED)
ntopic = 20
control_list = list(alpha=0.01, seed=SEED, burnin=1000, thin=100, iter=1000, best=FALSE)
model = LDA(dtm1, k = ntopic, control = control_list, method = "Gibbs")
best_model = model@fitted[[which.max(logLik(model))]]
## 各主題上的關鍵詞
term_no <- 10
topicterm = terms(best_model, term_no) %>%
t() %>%
as.data.frame(stringsAsFactors=FALSE) %>%
mutate(TopicName = rownames(.))
stopwords <- c("的", "在", "是", "都", "了", "之下", "不會",
"也", "很", "會", "有", "呢", "第二", "如何",
"嗎", "就", "但", "所", "我", "各項", "年來",
"不", "到", "要", "於", "表示", "增加", "而是",
"公里", "一名", "可能", "認為", "更是", "逐步",
"一次", "分享", "攝影", "繼續", "很多", "百年",
"這次", "近年", "特派記者", "隨著", "日益",
"就是", "沒有", "他們", "指出", "更加", "方面",
"整個", "任何", "不同", "本人", "充滿", "帶來",
"更好", "正在", "一天", "超過", "一直", "之外",
"再次", "對於", "曾經", "做出", "國人同胞",
"這塊", "儘管", "歷經", "如今", "各位伙伴",
"或者", "方式", "一向", "這樣", "各位鄉親",
"唯有", "來自", "英九", "一百年", "並且",
"登輝", "全體", "七年", "億元", "達到", "此外",
"絕對", "阿扁", "個人", "不管", "一切", "看到",
"親愛的國人同胞", "各位鄉親父老", "父老鄉親",
"什麼", "受到", "只有", "做到", "全體國人",
"起來", "我國", "民國", "年前", "所以", "謝謝",
"台灣人民", "願意", "相同", "依據", "院長",
"一方面", "同胞", "全國同胞", "決定", "如此",
"之間", "女士", "主席", "完全", "充分", "目前",
"只是", "始終", "通過", "大幅", "所謂", "之前",
"提高", "心中", "一部分", "不論是", "進一步",
"之際", "有關", "走過", "還有", "一塊", "三大",
"副總統", "相關", "各種", "甚至", "最近",
"打造一個", "以上", "然而", "兩千", "降到",
"因應", "需要", "由於", "當前", "最高", "一條",
"減少", "第一", "一位", "四年", "這種", "一代",
"全體國人同胞", "各位先進", "三年多", "非常",
"第三", "而且", "在於", "許多", "一起", "無法",
"包括", "因此", "各位貴賓", "大家好", "所有",
"今天是中華民國", "能夠", "不是", "不但",
"最大", "最後", "終於", "先生", "只要", "除了",
"一年", "當年", "之後", "一樣")
cr3 <- !(dtm$dimnames$Terms %in% stopwords)
length(which(cr3))
#統計出現總頻次大於20且出現系所數不大於1/4系所總數的詞語數
length(which(cr1 & cr2 & cr3))
#刪除詞語，保留文件-詞語矩陣上出現總頻次大於20且出現系所數不大於1/4系所總數的詞語
dtm1 <- dtm[, cr1&cr2&cr3]
#統計每一筆文件上出現的詞語數
doc.termno = row_sums(dtm1)
#是否有沒有詞語的文件
which(doc.termno<=5)
length(which(doc.termno<=5))
dtm1 <- dtm1[doc.termno>5, ]
news.df1 <- news.df[doc.termno>5, ]
#產生亂數
SEED = as.integer(Sys.time())%%10000
#根據亂數值，切分文件為十等分
set.seed(SEED)
fold = 10
folding = sample(rep(seq_len(fold), ceiling(nrow(dtm1)))[seq_len(nrow(dtm1))])
chain.list = seq_len(fold)
ntopic = 20
control_list = list(alpha=0.01, seed=SEED, burnin=1000, thin=100, iter=1000, best=FALSE)
model = LDA(dtm1, k = ntopic, control = control_list, method = "Gibbs")
best_model = model@fitted[[which.max(logLik(model))]]
## 各主題上的關鍵詞
term_no <- 10
topicterm = terms(best_model, term_no) %>%
t() %>%
as.data.frame(stringsAsFactors=FALSE) %>%
mutate(TopicName = rownames(.))
View(topicterm)
stopwords <- c("的", "在", "是", "都", "了", "之下", "不會",
"也", "很", "會", "有", "呢", "第二", "如何",
"嗎", "就", "但", "所", "我", "各項", "年來",
"不", "到", "要", "於", "表示", "增加", "而是",
"公里", "一名", "可能", "認為", "更是", "逐步",
"一次", "分享", "攝影", "繼續", "很多", "百年",
"這次", "近年", "特派記者", "隨著", "日益",
"就是", "沒有", "他們", "指出", "更加", "方面",
"整個", "任何", "不同", "本人", "充滿", "帶來",
"更好", "正在", "一天", "超過", "一直", "之外",
"再次", "對於", "曾經", "做出", "國人同胞",
"這塊", "儘管", "歷經", "如今", "各位伙伴",
"或者", "方式", "一向", "這樣", "各位鄉親",
"唯有", "來自", "英九", "一百年", "並且",
"登輝", "全體", "七年", "億元", "達到", "此外",
"絕對", "阿扁", "個人", "不管", "一切", "看到",
"親愛的國人同胞", "各位鄉親父老", "父老鄉親",
"什麼", "受到", "只有", "做到", "全體國人",
"起來", "我國", "民國", "年前", "所以", "謝謝",
"台灣人民", "願意", "相同", "依據", "院長",
"一方面", "同胞", "全國同胞", "決定", "如此",
"之間", "女士", "主席", "完全", "充分", "目前",
"只是", "始終", "通過", "大幅", "所謂", "之前",
"提高", "心中", "一部分", "不論是", "進一步",
"之際", "有關", "走過", "還有", "一塊", "三大",
"副總統", "相關", "各種", "甚至", "最近",
"打造一個", "以上", "然而", "兩千", "降到",
"因應", "需要", "由於", "當前", "最高", "一條",
"減少", "第一", "一位", "四年", "這種", "一代",
"全體國人同胞", "各位先進", "三年多", "非常",
"第三", "而且", "在於", "許多", "一起", "無法",
"包括", "因此", "各位貴賓", "大家好", "所有",
"今天是中華民國", "能夠", "不是", "不但",
"最大", "最後", "終於", "先生", "只要", "除了",
"一年", "當年", "之後", "一樣", "以來", "如果",
"才能", "還是", "現在")
cr3 <- !(dtm$dimnames$Terms %in% stopwords)
length(which(cr3))
#統計出現總頻次大於20且出現系所數不大於1/4系所總數的詞語數
length(which(cr1 & cr2 & cr3))
#刪除詞語，保留文件-詞語矩陣上出現總頻次大於20且出現系所數不大於1/4系所總數的詞語
dtm1 <- dtm[, cr1&cr2&cr3]
#統計每一筆文件上出現的詞語數
doc.termno = row_sums(dtm1)
#是否有沒有詞語的文件
which(doc.termno<=5)
length(which(doc.termno<=5))
dtm1 <- dtm1[doc.termno>5, ]
news.df1 <- news.df[doc.termno>5, ]
#產生亂數
SEED = as.integer(Sys.time())%%10000
#根據亂數值，切分文件為十等分
set.seed(SEED)
ntopic = 20
control_list = list(alpha=0.01, seed=SEED, burnin=1000, thin=100, iter=1000, best=FALSE)
model = LDA(dtm1, k = ntopic, control = control_list, method = "Gibbs")
best_model = model@fitted[[which.max(logLik(model))]]
## 各主題上的關鍵詞
term_no <- 10
topicterm = terms(best_model, term_no) %>%
t() %>%
as.data.frame(stringsAsFactors=FALSE) %>%
mutate(TopicName = rownames(.))
write.xlsx(topicterm, "president_talk_lda.xlsx", "term", row.names = FALSE)
View(topicterm)
stopwords <- c("的", "在", "是", "都", "了", "之下", "不會",
"也", "很", "會", "有", "呢", "第二", "如何",
"嗎", "就", "但", "所", "我", "各項", "年來",
"不", "到", "要", "於", "表示", "增加", "而是",
"公里", "一名", "可能", "認為", "更是", "逐步",
"一次", "分享", "攝影", "繼續", "很多", "百年",
"這次", "近年", "特派記者", "隨著", "日益",
"就是", "沒有", "他們", "指出", "更加", "方面",
"整個", "任何", "不同", "本人", "充滿", "帶來",
"更好", "正在", "一天", "超過", "一直", "之外",
"再次", "對於", "曾經", "做出", "國人同胞",
"這塊", "儘管", "歷經", "如今", "各位伙伴",
"或者", "方式", "一向", "這樣", "各位鄉親",
"唯有", "來自", "英九", "一百年", "並且",
"登輝", "全體", "七年", "億元", "達到", "此外",
"絕對", "阿扁", "個人", "不管", "一切", "看到",
"親愛的國人同胞", "各位鄉親父老", "父老鄉親",
"什麼", "受到", "只有", "做到", "全體國人",
"起來", "我國", "民國", "年前", "所以", "謝謝",
"台灣人民", "願意", "相同", "依據", "院長",
"一方面", "同胞", "全國同胞", "決定", "如此",
"之間", "女士", "主席", "完全", "充分", "目前",
"只是", "始終", "通過", "大幅", "所謂", "之前",
"提高", "心中", "一部分", "不論是", "進一步",
"之際", "有關", "走過", "還有", "一塊", "三大",
"副總統", "相關", "各種", "甚至", "最近",
"打造一個", "以上", "然而", "兩千", "降到",
"因應", "需要", "由於", "當前", "最高", "一條",
"減少", "第一", "一位", "四年", "這種", "一代",
"全體國人同胞", "各位先進", "三年多", "非常",
"第三", "而且", "在於", "許多", "一起", "無法",
"包括", "因此", "各位貴賓", "大家好", "所有",
"今天是中華民國", "能夠", "不是", "不但",
"最大", "最後", "終於", "先生", "只要", "除了",
"一年", "當年", "之後", "一樣", "以來", "如果",
"才能", "還是", "現在", "不要", "失去", "感到",
"不僅", "透過", "開始", "提出")
cr3 <- !(dtm$dimnames$Terms %in% stopwords)
length(which(cr3))
#統計出現總頻次大於20且出現系所數不大於1/4系所總數的詞語數
length(which(cr1 & cr2 & cr3))
#刪除詞語，保留文件-詞語矩陣上出現總頻次大於20且出現系所數不大於1/4系所總數的詞語
dtm1 <- dtm[, cr1&cr2&cr3]
#統計每一筆文件上出現的詞語數
doc.termno = row_sums(dtm1)
#是否有沒有詞語的文件
which(doc.termno<=5)
length(which(doc.termno<=5))
dtm1 <- dtm1[doc.termno>5, ]
news.df1 <- news.df[doc.termno>5, ]
#產生亂數
SEED = as.integer(Sys.time())%%10000
#根據亂數值，切分文件為十等分
set.seed(SEED)
fold = 10
ntopic = 20
control_list = list(alpha=0.01, seed=SEED, burnin=1000, thin=100, iter=1000, best=FALSE)
model = LDA(dtm1, k = ntopic, control = control_list, method = "Gibbs")
best_model = model@fitted[[which.max(logLik(model))]]
## 各主題上的關鍵詞
term_no <- 10
topicterm = terms(best_model, term_no) %>%
t() %>%
as.data.frame(stringsAsFactors=FALSE) %>%
mutate(TopicName = rownames(.))
View(topicterm)
stopwords <- c("的", "在", "是", "都", "了", "之下", "不會",
"也", "很", "會", "有", "呢", "第二", "如何",
"嗎", "就", "但", "所", "我", "各項", "年來",
"不", "到", "要", "於", "表示", "增加", "而是",
"公里", "一名", "可能", "認為", "更是", "逐步",
"一次", "分享", "攝影", "繼續", "很多", "百年",
"這次", "近年", "特派記者", "隨著", "日益",
"就是", "沒有", "他們", "指出", "更加", "方面",
"整個", "任何", "不同", "本人", "充滿", "帶來",
"更好", "正在", "一天", "超過", "一直", "之外",
"再次", "對於", "曾經", "做出", "國人同胞",
"這塊", "儘管", "歷經", "如今", "各位伙伴",
"或者", "方式", "一向", "這樣", "各位鄉親",
"唯有", "來自", "英九", "一百年", "並且",
"登輝", "全體", "七年", "億元", "達到", "此外",
"絕對", "阿扁", "個人", "不管", "一切", "看到",
"親愛的國人同胞", "各位鄉親父老", "父老鄉親",
"什麼", "受到", "只有", "做到", "全體國人",
"起來", "我國", "民國", "年前", "所以", "謝謝",
"台灣人民", "願意", "相同", "依據", "院長",
"一方面", "同胞", "全國同胞", "決定", "如此",
"之間", "女士", "主席", "完全", "充分", "目前",
"只是", "始終", "通過", "大幅", "所謂", "之前",
"提高", "心中", "一部分", "不論是", "進一步",
"之際", "有關", "走過", "還有", "一塊", "三大",
"副總統", "相關", "各種", "甚至", "最近",
"打造一個", "以上", "然而", "兩千", "降到",
"因應", "需要", "由於", "當前", "最高", "一條",
"減少", "第一", "一位", "四年", "這種", "一代",
"全體國人同胞", "各位先進", "三年多", "非常",
"第三", "而且", "在於", "許多", "一起", "無法",
"包括", "因此", "各位貴賓", "大家好", "所有",
"今天是中華民國", "能夠", "不是", "不但",
"最大", "最後", "終於", "先生", "只要", "除了",
"一年", "當年", "之後", "一樣", "以來", "如果",
"才能", "還是", "現在", "不要", "失去", "感到",
"不僅", "透過", "開始", "提出", "只要我們")
cr3 <- !(dtm$dimnames$Terms %in% stopwords)
length(which(cr3))
#統計出現總頻次大於20且出現系所數不大於1/4系所總數的詞語數
length(which(cr1 & cr2 & cr3))
#刪除詞語，保留文件-詞語矩陣上出現總頻次大於20且出現系所數不大於1/4系所總數的詞語
dtm1 <- dtm[, cr1&cr2&cr3]
#統計每一筆文件上出現的詞語數
doc.termno = row_sums(dtm1)
#是否有沒有詞語的文件
which(doc.termno<=5)
length(which(doc.termno<=5))
dtm1 <- dtm1[doc.termno>5, ]
news.df1 <- news.df[doc.termno>5, ]
#產生亂數
SEED = as.integer(Sys.time())%%10000
#根據亂數值，切分文件為十等分
set.seed(SEED)
ntopic = 20
control_list = list(alpha=0.01, seed=SEED, burnin=1000, thin=100, iter=1000, best=FALSE)
model = LDA(dtm1, k = ntopic, control = control_list, method = "Gibbs")
best_model = model@fitted[[which.max(logLik(model))]]
## 各主題上的關鍵詞
term_no <- 10
topicterm = terms(best_model, term_no) %>%
t() %>%
as.data.frame(stringsAsFactors=FALSE) %>%
mutate(TopicName = rownames(.))
View(topicterm)
write.xlsx(topicterm, "president_talk_lda.xlsx", "term", row.names = FALSE)
#主題內的詞語分布和文件內的主題分布
post_prob = posterior(best_model)
doc_topic_distr = post_prob$topics
doc_topic_distr.df = as.data.frame(doc_topic_distr)
colnames(doc_topic_distr.df) <- sprintf("Topic%02d", 1:20)
news.df1 <- news.df1 %>%
cbind(doc_topic_distr.df)
write.xlsx(news.df1, "president_talk_lda.xlsx", "speeches", row.names = FALSE, append=TRUE)
View(news.df1)
news.df2 <- news.df1 %>%
select(c(2, 3, 4, 7:26)) %>%
gather(key="Topics", value="Probability", -Year, -President, -Speech)
news.df2 %>%
group_by(President, Topics) %>%
summarise(Prob=mean(Probability)) %>%
ggplot() +
geom_col(aes(x=President, y=Prob, fill=President)) +
facet_wrap(~Topics, nrow=4)
news.df2 %>%
group_by(Speech, Topics) %>%
summarise(Prob=mean(Probability)) %>%
ggplot() +
geom_col(aes(x=Speech, y=Prob, fill=Speech)) +
facet_wrap(~Topics, nrow=4)
